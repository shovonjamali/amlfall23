{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - shallow learning\n",
    "\n",
    "Hi there! In this assignment, you will use shallow learning (including svm, random forests and gradient boosting if you feel up for the challenge) to solve an adapted Question 1 of the winter 2023 exam in applied machine learning:\n",
    "\n",
    "## Introduction:\n",
    "\n",
    "During the semester you have become very excited about the field of digital pathology which is an area that is developing rapidly due to advancements in microscopy imaging hardware. These advancements have allowed digitizing glass slides into whole-slide images. You have recently read the paper by [Veeling et al (2018)](https://arxiv.org/abs/1806.03962) and you are thrilled to see that the authors have derived a novel dataset, denoted PatchCamelyon (PCam), that will enable you to develop and benchmark your own machine learning models. As Veeling et al (2018) you are primarily interested in developing machine learning models that based on patches of whole-slide images of lymph node sections can assist pathologist in tumor detection. \n",
    "\n",
    "The primary objective of this exam is to perform image classification using the PCam dataset. The full dataset consists of 327,680 color images (96x96pxs) extracted from histopathologic scans of lymph node sections. Each image is annotated with a binary label indicating presence of metastatic tissue. For this assignment, however, you are only going to use the subset of the data which have been made available on Kaggle.\n",
    "\n",
    "### Question 1 (adapted from the exam):\n",
    "Use non-deep learning to perform image classification (tumor detection). Consider among other things the following:\n",
    "1. Support vector machines\n",
    "2. Random forests\n",
    "3. Boosting\n",
    "4. A combination of two or all three of the methods\n",
    "5. Assess the importance of image resolution for the methods you are using\n",
    "\n",
    "The assignment is posted as a Kaggle competition and is available here: https://www.kaggle.com/t/1f880200648443a3a30878d318cc6e4b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hints to get you started (with a very simple model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function that grayscale, resize and flattens the image. This function might also become handy (for deep learning later) if the original images are too large for your hardware configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sample(image):\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.resize(image,[32,32]).numpy()\n",
    "    image = image.reshape(1,-1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data features (observations,features): (26214, 1024)\n",
      "Shape of training data labels (observations,): (26214,)\n",
      "Shape of training data features (observations,features): (1638, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = np.load('Xtrain.npy') #/mnt/c/Users/cmd/Dropbox/Teaching/amlFall2023/assignments/Xtrain.npy\n",
    "X = np.vstack(list(map(convert_sample,X)))\n",
    "X = StandardScaler(with_mean=0, with_std=1).fit_transform(X)\n",
    "print(f'Shape of training data features (observations,features): {X.shape}')\n",
    "\n",
    "y = np.load('ytrain.npy') #/mnt/c/Users/cmd/Dropbox/Teaching/amlFall2023/assignments/ytrain.npy\n",
    "y = y.reshape(-1,)    \n",
    "print(f'Shape of training data labels (observations,): {y.shape}')\n",
    "\n",
    "Xtest = np.load('Xtest.npy') #/mnt/c/Users/cmd/Dropbox/Teaching/amlFall2023/assignments/Xtest.npy\n",
    "Xtest = np.vstack(list(map(convert_sample,Xtest)))\n",
    "Xtest = StandardScaler(with_mean=0, with_std=1).fit_transform(Xtest)\n",
    "print(f'Shape of training data features (observations,features): {Xtest.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is then ready to be applied for training and prediction in a shallow learning model such as the SVM classifier...below just a very very simple illustration on how to construct and train a support vector machine based on the data we have prepared. The predicted file can be submitted to Kaggle for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter searching\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Split the dataset into training and vslidation sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the SVM model\n",
    "classifier = svm.SVC()\n",
    "\n",
    "# Define the parameter grid to search\n",
    "#param_grid = {\n",
    "    #'C': [0.1, 1, 10, 100, 1000],\n",
    "    #'kernel': ['linear', 'rbf', 'poly'],\n",
    "    #'degree': [2, 3, 4],\n",
    "    #'gamma': ['scale', 'auto', 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "#}\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "#grid_search = GridSearchCV(estimator = classifier, param_grid = param_grid, scoring = 'accuracy', cv = 10)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "#grid_search = grid_search.fit(X, y)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "#grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "#best_params = grid_search.best_params_\n",
    "#print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Get the best SVM model from the grid search\n",
    "#best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "#y_pred = best_svm_model.predict(X_val)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "#accuracy = accuracy_score(y_val, y_pred)\n",
    "#print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "parameters = [\n",
    "    {'C': [0.1, 1, 10, 100, 1000], 'kernel': ['poly'], 'degree': [2, 3, 4]},\n",
    "    {'C': [0.1, 1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': ['scale', 'auto', 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]}\n",
    "]\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best accuracy from the grid search\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "# Get the best params from the grid search\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "\n",
    "# Get the best SVM model from the grid search\n",
    "#best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the validation set using the best model\n",
    "#y_pred = best_svm_model.predict(X_val)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "#accuracy = accuracy_score(y_val, y_pred)\n",
    "#print(\"Accuracy on validation:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the final model\n",
    "svm_optimal = svm.SVC(kernel='rbf', C = 100, gamma = 0.001) # update the params based on best params\n",
    "svm_optimal.fit(X, y)\n",
    "y_test_hat = svm_optimal.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_hat = pd.DataFrame({\n",
    "    'Id': list(range(len(y_test_hat))),\n",
    "    'Predicted': y_test_hat.reshape(-1,),\n",
    "})\n",
    "ytest_hat.to_csv('ytest_hat.csv', index=False) #/mnt/c/Users/cmd/Dropbox/Teaching/amlFall2023/assignments/ytest_hat.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
