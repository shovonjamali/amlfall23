{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBevGQQ3WW__"
   },
   "source": [
    "# Assignment - shallow learning\n",
    "\n",
    "Hi there! In this assignment, you will use shallow learning (including svm, random forests and gradient boosting if you feel up for the challenge) to solve an adapted Question 1 of the winter 2023 exam in applied machine learning:\n",
    "\n",
    "## Introduction:\n",
    "\n",
    "During the semester you have become very excited about the field of digital pathology which is an area that is developing rapidly due to advancements in microscopy imaging hardware. These advancements have allowed digitizing glass slides into whole-slide images. You have recently read the paper by [Veeling et al (2018)](https://arxiv.org/abs/1806.03962) and you are thrilled to see that the authors have derived a novel dataset, denoted PatchCamelyon (PCam), that will enable you to develop and benchmark your own machine learning models. As Veeling et al (2018) you are primarily interested in developing machine learning models that based on patches of whole-slide images of lymph node sections can assist pathologist in tumor detection.\n",
    "\n",
    "The primary objective of this exam is to perform image classification using the PCam dataset. The full dataset consists of 327,680 color images (96x96pxs) extracted from histopathologic scans of lymph node sections. Each image is annotated with a binary label indicating presence of metastatic tissue. For this assignment, however, you are only going to use the subset of the data which have been made available on Kaggle.\n",
    "\n",
    "### Question 1 (adapted from the exam):\n",
    "Use non-deep learning to perform image classification (tumor detection). Consider among other things the following:\n",
    "1. Support vector machines\n",
    "2. Random forests\n",
    "3. Boosting\n",
    "4. A combination of two or all three of the methods\n",
    "5. Assess the importance of image resolution for the methods you are using\n",
    "\n",
    "The assignment is posted as a Kaggle competition and is available here: https://www.kaggle.com/t/1f880200648443a3a30878d318cc6e4b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRNLUAX7WXAE"
   },
   "source": [
    "# Hints to get you started (with a very simple model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K4YTyTSKWXAF"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h8iGhy6WXAH"
   },
   "source": [
    "Defining a function that grayscale, resize and flattens the image. This function might also become handy (for deep learning later) if the original images are too large for your hardware configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UzlsPfsfWXAH"
   },
   "outputs": [],
   "source": [
    "def convert_sample(image):\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.resize(image,[32,32]).numpy()\n",
    "    image = image.reshape(1,-1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jM-u48X_WXAI",
    "outputId": "814922ea-d5e3-4ba6-8513-344c9cf26776"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data features (observations,features): (26214, 1024)\n",
      "Shape of training data labels (observations,): (26214,)\n",
      "Shape of training data features (observations,features): (1638, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = np.load('Xtrain.npy') \n",
    "X = np.vstack(list(map(convert_sample,X)))\n",
    "X = StandardScaler(with_mean=0, with_std=1).fit_transform(X)\n",
    "print(f'Shape of training data features (observations,features): {X.shape}')\n",
    "\n",
    "y = np.load('ytrain.npy') \n",
    "y = y.reshape(-1,)\n",
    "print(f'Shape of training data labels (observations,): {y.shape}')\n",
    "\n",
    "Xtest = np.load('Xtest.npy') \n",
    "Xtest = np.vstack(list(map(convert_sample,Xtest)))\n",
    "Xtest = StandardScaler(with_mean=0, with_std=1).fit_transform(Xtest)\n",
    "print(f'Shape of training data features (observations,features): {Xtest.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YJzX7bXWXAJ"
   },
   "source": [
    "The data is then ready to be applied for training and prediction in a shallow learning model such as the SVM classifier...below just a very very simple illustration on how to construct and train a support vector machine based on the data we have prepared. The predicted file can be submitted to Kaggle for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "ab6CY5SmFiw1",
    "outputId": "8b2de521-8fe2-4b8f-a10c-49157a44119e"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m voting_classifier\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m y_test_hat \u001b[38;5;241m=\u001b[39m \u001b[43mvoting_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:366\u001b[0m, in \u001b[0;36mVotingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    364\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoting \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 366\u001b[0m     maj \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# 'hard' voting\u001b[39;00m\n\u001b[0;32m    369\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(X)\n",
      "File \u001b[1;32mG:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:407\u001b[0m, in \u001b[0;36mVotingClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m    Weighted average probability for each class per sample.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    405\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    406\u001b[0m avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect_probas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights_not_none\n\u001b[0;32m    408\u001b[0m )\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg\n",
      "File \u001b[1;32mG:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:382\u001b[0m, in \u001b[0;36mVotingClassifier._collect_probas\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_collect_probas\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    381\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray([clf\u001b[38;5;241m.\u001b[39mpredict_proba(X) \u001b[38;5;28;01mfor\u001b[39;00m clf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_])\n",
      "File \u001b[1;32mG:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:382\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_collect_probas\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    381\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray([\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(X) \u001b[38;5;28;01mfor\u001b[39;00m clf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_])\n",
      "File \u001b[1;32mG:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\utils\\_available_if.py:31\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     25\u001b[0m attr_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(owner\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[0;32m     33\u001b[0m     out \u001b[38;5;241m=\u001b[39m MethodType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, obj)\n",
      "File \u001b[1;32mG:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:827\u001b[0m, in \u001b[0;36mBaseSVC._check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability:\n\u001b[1;32m--> 827\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    828\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba is not available when  probability=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    829\u001b[0m         )\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnu_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba only implemented for SVC and NuSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "# Create individual classifiers\n",
    "svm_classifier = svm.SVC(\n",
    "    kernel='rbf', \n",
    "    C=100,\n",
    "    probability=True\n",
    ")\n",
    "\n",
    "rf_classifier = ensemble.RandomForestClassifier(\n",
    "    n_estimators=500, \n",
    "    min_samples_split=20, \n",
    "    min_samples_leaf=5\n",
    ")\n",
    "\n",
    "gb_classifier = ensemble.GradientBoostingClassifier(\n",
    "    n_estimators=500,\n",
    "    min_samples_split=25,\n",
    "    min_samples_leaf=5\n",
    ")\n",
    "\n",
    "# Create a VotingClassifier with 'soft' voting\n",
    "voting_classifier = ensemble.VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', svm_classifier),\n",
    "        ('rf', rf_classifier),\n",
    "        ('gb', gb_classifier)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_classifier.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_test_hat = voting_classifier.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q8NTmNElWXAL"
   },
   "outputs": [],
   "source": [
    "ytest_hat = pd.DataFrame({\n",
    "    'Id': list(range(len(y_test_hat))),\n",
    "    'Predicted': y_test_hat.reshape(-1,),\n",
    "})\n",
    "ytest_hat.to_csv('ytest_hat.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
