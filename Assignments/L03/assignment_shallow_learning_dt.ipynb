{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBevGQQ3WW__"
   },
   "source": [
    "# Assignment - shallow learning\n",
    "\n",
    "Hi there! In this assignment, you will use shallow learning (including svm, random forests and gradient boosting if you feel up for the challenge) to solve an adapted Question 1 of the winter 2023 exam in applied machine learning:\n",
    "\n",
    "## Introduction:\n",
    "\n",
    "During the semester you have become very excited about the field of digital pathology which is an area that is developing rapidly due to advancements in microscopy imaging hardware. These advancements have allowed digitizing glass slides into whole-slide images. You have recently read the paper by [Veeling et al (2018)](https://arxiv.org/abs/1806.03962) and you are thrilled to see that the authors have derived a novel dataset, denoted PatchCamelyon (PCam), that will enable you to develop and benchmark your own machine learning models. As Veeling et al (2018) you are primarily interested in developing machine learning models that based on patches of whole-slide images of lymph node sections can assist pathologist in tumor detection.\n",
    "\n",
    "The primary objective of this exam is to perform image classification using the PCam dataset. The full dataset consists of 327,680 color images (96x96pxs) extracted from histopathologic scans of lymph node sections. Each image is annotated with a binary label indicating presence of metastatic tissue. For this assignment, however, you are only going to use the subset of the data which have been made available on Kaggle.\n",
    "\n",
    "### Question 1 (adapted from the exam):\n",
    "Use non-deep learning to perform image classification (tumor detection). Consider among other things the following:\n",
    "1. Support vector machines\n",
    "2. Random forests\n",
    "3. Boosting\n",
    "4. A combination of two or all three of the methods\n",
    "5. Assess the importance of image resolution for the methods you are using\n",
    "\n",
    "The assignment is posted as a Kaggle competition and is available here: https://www.kaggle.com/t/1f880200648443a3a30878d318cc6e4b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRNLUAX7WXAE"
   },
   "source": [
    "# Hints to get you started (with a very simple model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K4YTyTSKWXAF"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h8iGhy6WXAH"
   },
   "source": [
    "Defining a function that grayscale, resize and flattens the image. This function might also become handy (for deep learning later) if the original images are too large for your hardware configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UzlsPfsfWXAH"
   },
   "outputs": [],
   "source": [
    "def convert_sample(image):\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.resize(image,[32,32]).numpy()\n",
    "    image = image.reshape(1,-1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jM-u48X_WXAI",
    "outputId": "814922ea-d5e3-4ba6-8513-344c9cf26776"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data features (observations,features): (26214, 1024)\n",
      "Shape of training data labels (observations,): (26214,)\n",
      "Shape of training data features (observations,features): (1638, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ML_Practice\\amlfall23\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = np.load('Xtrain.npy') \n",
    "X = np.vstack(list(map(convert_sample,X)))\n",
    "X = StandardScaler(with_mean=0, with_std=1).fit_transform(X)\n",
    "print(f'Shape of training data features (observations,features): {X.shape}')\n",
    "\n",
    "y = np.load('ytrain.npy') \n",
    "y = y.reshape(-1,)\n",
    "print(f'Shape of training data labels (observations,): {y.shape}')\n",
    "\n",
    "Xtest = np.load('Xtest.npy') \n",
    "Xtest = np.vstack(list(map(convert_sample,Xtest)))\n",
    "Xtest = StandardScaler(with_mean=0, with_std=1).fit_transform(Xtest)\n",
    "print(f'Shape of training data features (observations,features): {Xtest.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YJzX7bXWXAJ"
   },
   "source": [
    "The data is then ready to be applied for training and prediction in a shallow learning model such as the SVM classifier...below just a very very simple illustration on how to construct and train a support vector machine based on the data we have prepared. The predicted file can be submitted to Kaggle for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "ab6CY5SmFiw1",
    "outputId": "8b2de521-8fe2-4b8f-a10c-49157a44119e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [7:36:00<00:00, 9120.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Accuracy  n_estimators  min_samples_split  min_samples_leaf\n",
      "0   0.750715            50                 15                 5\n",
      "1   0.745566            50                 15                10\n",
      "2   0.747473            50                 15                15\n",
      "3   0.750715            50                 20                 5\n",
      "4   0.745566            50                 20                10\n",
      "5   0.747473            50                 20                15\n",
      "6   0.750715            50                 25                 5\n",
      "7   0.745566            50                 25                10\n",
      "8   0.747473            50                 25                15\n",
      "9   0.771696           200                 15                 5\n",
      "10  0.772840           200                 15                10\n",
      "11  0.768644           200                 15                15\n",
      "12  0.771886           200                 20                 5\n",
      "13  0.772840           200                 20                10\n",
      "14  0.768644           200                 20                15\n",
      "15  0.774175           200                 25                 5\n",
      "16  0.775701           200                 25                10\n",
      "17  0.768644           200                 25                15\n",
      "18  0.779325           500                 15                 5\n",
      "19  0.780088           500                 15                10\n",
      "20  0.779516           500                 15                15\n",
      "21  0.778180           500                 20                 5\n",
      "22  0.780088           500                 20                10\n",
      "23  0.779516           500                 20                15\n",
      "24  0.783139           500                 25                 5\n",
      "25  0.781232           500                 25                10\n",
      "26  0.779516           500                 25                15\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter searching\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and vslidation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "min_samples_split_list = [5, 10] \n",
    "min_samples_leaf_list = [5, 10] \n",
    "max_features_list = [5, 10] \n",
    "\n",
    "results = []\n",
    "\n",
    "for min_samples_split in tqdm.tqdm(min_samples_split_list):\n",
    "    for min_samples_leaf in min_samples_leaf_list:\n",
    "        for max_features in max_features_list:\n",
    "            dt_current = tree.DecisionTreeClassifier(\n",
    "                min_samples_split=min_samples_split,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                max_features=max_features,\n",
    "                )\n",
    "            dt_current = dt_current.fit(X_train, y_train)\n",
    "            y_val_hat = dt_current.predict(X_val)\n",
    "            accuracy = accuracy_score(y_val_hat, y_val)\n",
    "\n",
    "            results.append([accuracy, min_samples_split, min_samples_leaf, max_features])\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.columns = ['Accuracy', 'min_samples_split', 'min_samples_leaf', 'max_features']\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XVxF9Wt3Hzoe"
   },
   "outputs": [],
   "source": [
    "# Extract best parameters\n",
    "min_samples_split = results.loc[results['Accuracy'].idxmax()]['min_samples_split'].astype(int)\n",
    "min_samples_leaf = results.loc[results['Accuracy'].idxmax()]['min_samples_leaf'].astype(int)\n",
    "max_features = results.loc[results['Accuracy'].idxmax()]['max_features'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "25\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(min_samples_split)\n",
    "print(min_samples_leaf)\n",
    "print(max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rcv5ymJmWXAK"
   },
   "outputs": [],
   "source": [
    "# Initialize your final model\n",
    "dt_optimized = tree.DecisionTreeClassifier(\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    max_features=max_features,\n",
    "    )\n",
    "\n",
    "dt_optimized.fit(X, y)\n",
    "\n",
    "y_test_hat = dt_optimized.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q8NTmNElWXAL"
   },
   "outputs": [],
   "source": [
    "ytest_hat = pd.DataFrame({\n",
    "    'Id': list(range(len(y_test_hat))),\n",
    "    'Predicted': y_test_hat.reshape(-1,),\n",
    "})\n",
    "ytest_hat.to_csv('ytest_hat.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
