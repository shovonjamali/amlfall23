{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - SVM for regression\n",
    "\n",
    "1. Standardize the data and implement a linear, polynomial, and RBF SVM. What is the performance (MSE) of each model now? Is the linear model still best?\n",
    "1. Try to split your training data (again using $\\texttt{train_test_split}$) to obtain a validation set. Try to optimize the performance of your model on the validation data, focusing particularly on regularization ($C$). Can you achieve test MSE below 10 (this is not trivial!)? In the original paper, they achieve an MSE of 7.2 (although it is not directly comparable). Remember to use standadization!\n",
    "\n",
    "**Note**: Large values of $C$ may be VERY slow to fit (for some of the models)! Try not to go too extreme, as your code may crash.\n",
    "\n",
    "**See slides for more details!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 11) (79, 11) (315,) (79,)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.datasets import load_boston # NOTE how we use the Boston data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error # NOTE how we use a new metric!\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = './data/HousingData.csv'\n",
    "raw_df = pd.read_csv(data).dropna()\n",
    "\n",
    "y = raw_df.values[:, 2]\n",
    "X = raw_df.values[:, 3:]\n",
    "\n",
    "#X, y = load_boston(return_X_y=True) # `load_boston` has been removed from scikit-learn since version 1.2.\n",
    "\n",
    "# Use `train_test_split` to split your data into a train and a test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Standardize the data and implement a linear, polynomial, and RBF SVM. What is the performance (MSE) of each model now? Is the linear model still best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will call the standardized X for Z.\n",
    "# It is important, that you only fit your scaler on your training and not your test data!\n",
    "# This is akin to when you fit your model - you do not want to \"peak\" at the test data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Z_train = scaler.fit_transform(X_train)\n",
    "Z_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM achieved 16.74 MSE.\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "svm_linear = svm.SVR(kernel='linear')\n",
    "svm_linear.fit(Z_train, y_train) # remember fit to Z_train, NOT X_train\n",
    "\n",
    "# ... and predicting\n",
    "y_test_hat_linear = svm_linear.predict(Z_test) # And Z_test here instead of X_test\n",
    "mse_linear = mean_squared_error(y_test_hat_linear, y_test)\n",
    "print(f'Linear SVM achieved {round(mse_linear, 3)} MSE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial SVM achieved 30.633 MSE.\n"
     ]
    }
   ],
   "source": [
    "# Polynomial SVM (you decide degree)\n",
    "svm_poly = svm.SVR(kernel='poly', degree=2)\n",
    "svm_poly.fit(Z_train, y_train)\n",
    "\n",
    "# ... and predicting\n",
    "y_test_hat_poly = svm_poly.predict(Z_test)\n",
    "mse_poly = mean_squared_error(y_test_hat_poly, y_test)\n",
    "print(f'Polynomial SVM achieved {round(mse_poly, 3)} MSE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVM achieved 12.779 MSE.\n"
     ]
    }
   ],
   "source": [
    "svm_rbf = svm.SVR(kernel='rbf')\n",
    "svm_rbf.fit(Z_train, y_train)\n",
    "\n",
    "# ... and predicting\n",
    "y_test_hat_rbf = svm_rbf.predict(Z_test)\n",
    "mse_rbf = mean_squared_error(y_test_hat_rbf, y_test)\n",
    "print(f'RBF SVM achieved {round(mse_rbf, 3)} MSE.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Try to split your training data (again using $\\texttt{train_test_split}$) to obtain a validation set. Try to optimize the performance of your model on the validation data, focusing particularly on regularization ($C$). Can you achieve test MSE below 10 (this is not trivial!)? In the original paper, they achieve an MSE of 7.2 (although it is not directly comparable). Remember to use standadization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 11) (63, 11) (79, 11) (252,) (63,) (79,)\n"
     ]
    }
   ],
   "source": [
    "# Start by splitting the train data to also obtain validation data\n",
    "Z_train, Z_val, y_train, y_val = train_test_split(Z_train, y_train, test_size=0.2, random_state=42)\n",
    "print(Z_train.shape, Z_val.shape, Z_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MSE  Kernel        C  epsilon\n",
      "0   46.227528  linear    0.001     0.01\n",
      "1   43.848799  linear    0.001     1.00\n",
      "2   14.727000  linear    0.500     0.01\n",
      "3   13.971696  linear    0.500     1.00\n",
      "4   14.545967  linear    1.000     0.01\n",
      "5   13.044947  linear    1.000     1.00\n",
      "6   13.190397  linear   10.000     0.01\n",
      "7   13.196421  linear   10.000     1.00\n",
      "8   13.260039  linear  100.000     0.01\n",
      "9   13.198375  linear  100.000     1.00\n",
      "10  56.179933    poly    0.001     0.01\n",
      "11  52.872447    poly    0.001     1.00\n",
      "12  21.900023    poly    0.500     0.01\n",
      "13  22.188300    poly    0.500     1.00\n",
      "14  22.277434    poly    1.000     0.01\n",
      "15  21.558435    poly    1.000     1.00\n",
      "16  24.992528    poly   10.000     0.01\n",
      "17  19.395817    poly   10.000     1.00\n",
      "18  28.791545    poly  100.000     0.01\n",
      "19  22.473270    poly  100.000     1.00\n",
      "20  56.936973     rbf    0.001     0.01\n",
      "21  53.603987     rbf    0.001     1.00\n",
      "22  18.384409     rbf    0.500     0.01\n",
      "23  18.928444     rbf    0.500     1.00\n",
      "24  16.010162     rbf    1.000     0.01\n",
      "25  16.122782     rbf    1.000     1.00\n",
      "26  10.040584     rbf   10.000     0.01\n",
      "27  10.881587     rbf   10.000     1.00\n",
      "28   7.380123     rbf  100.000     0.01\n",
      "29   7.184748     rbf  100.000     1.00\n"
     ]
    }
   ],
   "source": [
    "# Now try different values of kernels, C, epsilon, as well as any other settings you want to tune\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf'] # input values seperated by \",\".\n",
    "Cs = [0.001, 0.5, 1, 10, 100] # input values seperated by \",\".\n",
    "epsilons = [0.01, 1] # input values seperated by \",\".\n",
    "\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    for C in Cs:\n",
    "        for epsilon in epsilons:\n",
    "            svm_current = svm.SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
    "            svm_current.fit(Z_train, y_train)\n",
    "            y_val_hat = svm_current.predict(Z_val)\n",
    "            mse = mean_squared_error(y_val_hat, y_val)\n",
    "\n",
    "            results.append([mse, kernel, C, epsilon])\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.columns = ['MSE', 'Kernel', 'C', 'epsilon']\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>Kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.184748</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE Kernel      C  epsilon\n",
       "29  7.184748    rbf  100.0      1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best parameters.\n",
    "results[results['MSE'] == results['MSE'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized SVM achieved 3.811 MSE.\n"
     ]
    }
   ],
   "source": [
    "# Initialize your final model\n",
    "svm_optimized = svm.SVR(kernel='rbf', C=100, epsilon=1)\n",
    "\n",
    "# Use both training and validation data to fit it (np.concatenate \"stacks\" the array like rbind in R)\n",
    "svm_optimized.fit(np.concatenate([Z_train, Z_val]), np.concatenate([y_train, y_val]))\n",
    "\n",
    "# Predict on test data\n",
    "y_val_hat_optimized = svm_optimized.predict(Z_test)\n",
    "\n",
    "# Obtain and check accuracy on test data\n",
    "accuracy_optimized = mean_squared_error(y_val_hat_optimized, y_test)\n",
    "print(f'Optimized SVM achieved {round(accuracy_optimized, 3)} MSE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
